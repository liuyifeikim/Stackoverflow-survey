---
title: "SURVEY2019"
output: html_document
---

1、caret并行计算
2、h2o

```{r 载入相关库}
library(tidyverse)
library(tidytext)
library(caret)
library(tictoc)
library(parallel)
library(doParallel)
library(randomForest)
```

```{r 读入数据}
survey_2019 <- read_csv("../../../DATA/developer_survey_2019/survey_results_public.csv", col_names = TRUE)
survey_2019
glimpse(survey_2019)
```

```{r 编程语言使用}
#在使用的语言及明年想学的语言
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  gather(key = type, value = lang_list, LanguageWorkedWith:LanguageDesireNextYear) %>% 
  unnest_tokens(input = lang_list, output = lang, token = "regex", pattern = ";") %>% 
  count(type, lang) %>% 
  spread(key = type, value = n) %>% 
  select(lang, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  filter(!is.na(lang)) %>% 
  mutate(new_rate = LanguageDesireNextYear / LanguageWorkedWith) %>% 
  arrange(-new_rate)


#排除明年想学但现在已经在用的语言：新学习指数
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  gather(key = type, value = lang_list, LanguageWorkedWith:LanguageDesireNextYear) %>% 
  unnest_tokens(input = lang_list, output = lang, token = "regex", pattern = ";") %>% 
  arrange(Respondent, desc(type), lang) %>%        #将目前在用的排在前面
  distinct(Respondent, lang, .keep_all = TRUE) %>% #保留其他没有处理的列
  count(type, lang) %>% 
  spread(key = type, value = n) %>% 
  select(lang, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  filter(!is.na(lang)) %>% 
  mutate(new_rate = LanguageDesireNextYear / LanguageWorkedWith) %>% 
  arrange(-new_rate)
```
排除现在在学明年继续学的记录，仅考虑没有用，明年想新学的情况，将两个频数相除，构建每种语言的从零学习指数，指数数值越高说明该语言现在没有用但之后想学的人越多，说明该语言的流行程度正处在上升阶段。

```{r 生成当前在用工具二分变量矩阵和结果变量}
#自变量
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith) %>% 
  unnest_tokens(input = LanguageWorkedWith, output = lang, token = "regex", pattern = ";") %>% 
  count(Respondent, lang) %>% 
  spread(key = lang, value = n, fill = 0) %>% 
  select(-c(`<NA>`)) -> x_tbl
x_tbl

#因变量
survey_2019 %>%   
  select(Respondent, LanguageDesireNextYear) %>% 
  unnest_tokens(input = LanguageDesireNextYear, output = lang, token = "regex", pattern = ";") %>% 
  filter(lang == "r") %>% 
  select(Respondent)-> y_tbl  #仅保留ID
y_tbl

#两者合并
x_tbl %>% 
  mutate(r_yn = as.factor(ifelse(Respondent %in% y_tbl$Respondent, 1, 0))) %>% 
  select(-Respondent) -> model_wide
model_wide

#因变量分布
model_wide %>% count(r_yn)
```

```{r 划分训练和测试集}
set.seed(100)
train_id <- createDataPartition(model_wide$r_yn, p = 0.7, list = FALSE)
train <- model_wide[train_id,]
test <- model_wide[-train_id,]
dim(train)
dim(test)
table(train$r_yn) %>% prop.table()
table(test$r_yn) %>% prop.table()
```


```{r 使用caret进行训练}
#看有哪些可调整的参数
modelLookup("rf")

#设定交叉检验方案
cv_ctrl <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
```


```{r 使用caret进行训练}
#模型训练并计算时间
tic()
set.seed(100)
model_rf <- train(
  r_yn ~ .,
  data = train,
  method = "rf",
  trControl = cv_ctrl,
  metric = "f1"
)
toc()

#查看结果
model_rf
```

```{r 并行训练}
#设定集群
cl <- makeCluster(12)
registerDoParallel(cl)

#训练模型
tic()
set.seed(100)
model_rf_par <- train(
  r_yn ~ .,
  data = train,
  method = "rf",
  trControl = cv_ctrl
)
toc()

#停止集群
stopCluster(cl)

#查看结果
model_rf_par
```


---
title: "SURVEY2019"
output: html_document
---

1、caret并行计算
2、summaryFunction = prSummary
2、网格搜索和随机搜索
3、h2o

```{r 载入相关库}
library(tidyverse)
library(tidytext)
library(caret)
library(tictoc)
library(parallel)
library(doParallel)
library(randomForest)
library(mlbench) #ranger
library(pryr)
```

```{r 读入数据}
survey_2019 <- read_csv("../../../DATA/developer_survey_2019/survey_results_public.csv", col_names = TRUE)
survey_2019
glimpse(survey_2019)
```

```{r 编程语言使用}
#在使用的语言及明年想学的语言
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  gather(key = type, value = lang_list, LanguageWorkedWith:LanguageDesireNextYear) %>% 
  unnest_tokens(input = lang_list, output = lang, token = "regex", pattern = ";") %>% 
  count(type, lang) %>% 
  spread(key = type, value = n) %>% 
  select(lang, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  filter(!is.na(lang)) %>% 
  mutate(new_rate = LanguageDesireNextYear / LanguageWorkedWith) %>% 
  arrange(-new_rate)


#排除明年想学但现在已经在用的语言：新学习指数
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  gather(key = type, value = lang_list, LanguageWorkedWith:LanguageDesireNextYear) %>% 
  unnest_tokens(input = lang_list, output = lang, token = "regex", pattern = ";") %>% 
  arrange(Respondent, desc(type), lang) %>%        #将目前在用的排在前面
  distinct(Respondent, lang, .keep_all = TRUE) %>% #保留其他没有处理的列
  count(type, lang) %>% 
  spread(key = type, value = n) %>% 
  select(lang, LanguageWorkedWith, LanguageDesireNextYear) %>% 
  filter(!is.na(lang)) %>% 
  mutate(new_rate = LanguageDesireNextYear / LanguageWorkedWith) %>% 
  arrange(-new_rate)
```
排除现在在学明年继续学的记录，仅考虑没有用，明年想新学的情况，将两个频数相除，构建每种语言的从零学习指数，指数数值越高说明该语言现在没有用但之后想学的人越多，说明该语言的流行程度正处在上升阶段。

```{r 生成当前在用工具二分变量矩阵和结果变量}
#自变量
survey_2019 %>% 
  select(Respondent, LanguageWorkedWith) %>% 
  unnest_tokens(input = LanguageWorkedWith, output = lang, token = "regex", pattern = ";") %>% 
  count(Respondent, lang) %>% 
  spread(key = lang, value = n, fill = 0) %>% 
  select(-c(`<NA>`, "r")) -> x_tbl
x_tbl

#因变量
survey_2019 %>%   
  select(Respondent, LanguageDesireNextYear) %>% 
  unnest_tokens(input = LanguageDesireNextYear, output = lang, token = "regex", pattern = ";") %>% 
  filter(lang == "r") %>% 
  select(Respondent)-> y_tbl  #仅保留ID
y_tbl

#两者合并
x_tbl %>% 
  mutate(r_yn = factor(ifelse(Respondent %in% y_tbl$Respondent, "yes", "no"),levels = c("yes", "no"))) %>% 
  select(-Respondent) -> model_wide #需要将因变量处理成因子，而且要有字符，如果只是0/1后面用ROC选模型会报错
model_wide

#因变量分布
model_wide %>% count(r_yn)
levels(model_wide$r_yn)
```

```{r 划分训练和测试集}
set.seed(100)
train_id <- createDataPartition(model_wide$r_yn, p = 0.7, list = FALSE)
train <- model_wide[train_id,]
test <- model_wide[-train_id,]
dim(train)
dim(test)
table(train$r_yn)
table(test$r_yn)
table(train$r_yn) %>% prop.table()
table(test$r_yn) %>% prop.table()
```


```{r 使用caret进行训练}
#看有哪些可调整的参数
modelLookup("rf")

#设定交叉检验方案
cv_ctrl <- trainControl(method = "cv", 
                        number = 5, 
                        verboseIter = TRUE)

#可以用F值、precision、recall、auc
cv_ctrl_pr <- trainControl(method = "cv", 
                           number = 5, 
                           summaryFunction = prSummary,
                           verboseIter = TRUE)

#可以用AUC
cv_ctrl_two <- trainControl(method = "cv", 
                            number = 5, 
                            summaryFunction = twoClassSummary,
                            classProbs = TRUE,
                            verboseIter = TRUE)
```


```{r 使用caret进行训练}
# #模型训练并计算时间
# tic()
# set.seed(100)
# model_rf <- train(
#   r_yn ~ .,
#   data = train,
#   method = "rf",
#   trControl = cv_ctrl
# )
# toc()
# 
# #查看结果
# model_rf
```


```{r 并行训练：rf}
#设定集群
cl_12 <- makeCluster(12)
registerDoParallel(cl_12)

#训练模型
tic()
set.seed(100)
model_rf_par <- train(
  r_yn ~ .,
  data = train,
  method = "rf",  #默认500棵树
  trControl = cv_ctrl_pr,
  metric = "F"   #会默认将level中的第1个作为阳性样本计算
)
toc()

#停止集群
stopCluster(cl)

#查看结果
model_rf_par
plot(model_rf_par)

#变量重要性
varImp(model_rf_par)
```
与非并行方案相比，用12线程的并行方案大概只使用了一半时间。

```{r 测试集性能评估}
y_pred_rf <- predict(model_rf_par, test)
confusionMatrix(y_pred_rf, test$r_yn, positive = "1", mode = "prec_recall")
```

```{r 并行训练：mlbench库}
#设定集群
cl_12 <- makeCluster(12)
registerDoParallel(cl_12)

#训练模型
tic()
set.seed(100)
model_ranger_par <- train(
  r_yn ~ .,
  data = train,
  method = "ranger",
  trControl = cv_ctrl_pr,
  metric = "F"
)
toc()

#停止集群
stopCluster(cl_12)

#查看结果
model_ranger_par
plot(model_ranger_par)
```
使用ranger库要比使用randomforest库运行速度要快

```{r 测试集性能评估}
y_pred_ranger <- predict(model_ranger_par, test)
confusionMatrix(y_pred_ranger, test$r_yn, positive = "1", mode = "prec_recall")
```

```{r 参数调整, grid方法}
#设定参数范围
grid <- data.frame(mtry = seq(1, ncol(train), by = 2),
                   splitrule = "gini",
                   min.node.size = 1)  #等同于expand.grid

#设定集群
cl_12 <- makeCluster(12)
registerDoParallel(cl_12)

#训练模型
tic()
set.seed(100)
model_ranger_par_tune <- train(
  r_yn ~ .,
  data = train,
  method = "ranger",     #默认500棵树
  trControl = cv_ctrl_two,
  metric = "ROC",
  tuneGrid = grid
)
toc()

#停止集群
stopCluster(cl_12)

#查看结果
model_ranger_par_tune
plot(model_ranger_par_tune)
```


